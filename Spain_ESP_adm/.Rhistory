quijote %>%
filter(!str_detect(word, "[aeiouáéíóúü]"))
#str_count() tells you how many matches there are in a string:
#Good for using in a mutate
quijote$word %>%
str_count("a")
quijote$word %>%
str_count("a") %>%
mean()
quijote %>%
mutate(number_a = str_count(word, "a"))
str_count("abababa", "aba")
str_view_all("abababa", "aba")
#str_extract() extracts the exact match (not the string where it is found)
verne %>%
mutate(fem_noun = str_extract(sentences, "\\bla\\b\\s\\w+\\b"))
#all matches, in different columns
verne %>%
mutate(fem_noun = str_extract_all(sentences, "\\bla\\b\\s\\w+\\b", simplify = TRUE))
library(tidyverse)
library(cld2)
library(cld3)
library(textcat)
library(franc)
corpus_folder <- "~/Documents/Corpus PostScriptum/Descargado/ES1500_ORIG_TXT/"
corpus_folder %>%
map_dfr(read_delim, delim = "\t", col_names = "text", .id = "source")
corpus_files <- dir_ls(data_dir)
#library(tidytext)
sessionInfo()
library(fs)
corpus_folder <- "~/Documents/Corpus PostScriptum/Descargado/ES1500_ORIG_TXT/"
corpus_files <- dir_ls(data_dir)
corpus_files <- dir_ls(corpus_folder)
corpus_files %>%
map_dfr(read_delim, delim = "\t", col_names = "text", .id = "source")
corpus_files %>%
map_dfr(read_delim, delim = "\t", col_names = "text", .id = "source") %>%
mutate(source = str_replace(source, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES1500_ORIG_TXT/", ""))
?dir
?dir()
infolder <- "~/Documents/Corpus PostScriptum/Descargado/"
data_frame(file = dir(infolder, full.names = TRUE))
tibble(file = dir(infolder, full.names = TRUE))
tibble(file = dir(infolder, full.names = TRUE)) %>%
mutate(text = map(file, read_lines))
tibble(file = dir(infolder, full.names = TRUE)) %>%
mutate(text = map(file, dir_ls))
tibble(file = dir(infolder, full.names = TRUE)) %>%
mutate(text = map(file, dir_ls)) %>%
unnest(text)
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text)
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(source = str_replace(source, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
folder = str_replace(folder, "_ORIG_", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
folder = str_replace(folder, "_ORIG_TXT", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
folder = str_replace(folder, "_ORIG_TXT", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES1[5678]00_ORIG_TXT", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
folder = str_replace(folder, "_ORIG_TXT", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES1[5678]00_ORIG_TXT/", ""))
tibble(folder = dir(infolder, full.names = TRUE)) %>%
mutate(file = map(folder, dir_ls)) %>%
unnest(file) %>%
mutate(text = map(file, read_lines)) %>%
unnest(text) %>%
mutate(folder = str_replace(folder, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
folder = str_replace(folder, "_ORIG_TXT", ""),
file = str_replace(file, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES1[5678]00_ORIG_TXT/", ""),
file = str_replace(file, ".txt", ""))
tibble(century = dir(infolder, full.names = TRUE)) %>%
mutate(textID = map(century, dir_ls)) %>%
unnest(textID) %>%
mutate(text = map(textID, read_lines)) %>%
unnest(text) %>%
mutate(century = str_replace(century, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado//ES", ""),
century = str_replace(century, "_ORIG_TXT", ""),
textID = str_replace(textID, "/Users/carlotadebenitomoreno/Documents/Corpus PostScriptum/Descargado/ES1[5678]00_ORIG_TXT/", ""),
textID = str_replace(textID, ".txt", ""))
install.packages("swirl")
library(swirl)
install_course_github(
"Carlotadbm",
"Tools_for_text_analysis")
swirl()
swirl()
swirl()
library(tidyverse)
library(tidytext)
?unnest_tokens
library(swirl)
swirl()
quijote
verne
str_detect(quijote$word, "$a")
str_detect(quijote$word, "^a")
str_detect(quijote$word, "^a") %>% sum()
str_detect(quijote$word, "^a") %>% mean()
quijote %>% mutate(starts_a = str_detect(word, "^a"))
quijote %>% filter(str_detect(word, "^a"))
quijote %>% filter(!str_detect(word, "[aeiouáéíóúü]"))
str_count(quijote$word, "a")
str_count(quijote$word, "a") %>% mean()
quijote %>% mutate(number_a = str_count(word, "a"))
str_count("abababa", "aba")
str_view_all("abababa", "aba")
skip()
swirl()
library(swirlify)
demo_lesson()
demo_lesson(15)
demo_lesson(18)
demo_lesson(21)
skip()
demo_lesson(22)
skip()
demo_lesson(22)
verne %>% mutate(fem_noun = str_extract(sentences, "\\bla\\b\\s\\w+\\b"))
demo_lesson(22)
verne %>% mutate(fem_noun = str_extract(sentences, "\\bla\\b\\s\\w+\\b"))
test_lesson()
demo_lesson(22)
skip()
skip()
skip()
skip()
skip()
skip()
skip()
library(swirlify)
test_lesson()
swirl()
demo_lesson()
skip()
library(swirl)
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
install.packages("swirl")
library(swirl)
install_course_github(
"Carlotadbm",
"Tools_for_text_analysis")
swirl()
library(tidyverse)
#library(XML)
library(xml2)
file_url2 <- "https://raw.githubusercontent.com/noe-eva/NOAH-Corpus/master/blick.xml"
data2 <- read_xml(file_url2)
xml_structure(data2)
xml_find_all(data2, "//s") #finds all s objects
sentences <- xml_find_all(data2, "//s") #finds all s objects
xml_text(sentences) #extracts content from arguments It reads the sentences without spaces :/
#xml_double
#xml_integer #also exist
as_list(sentences) #extracts content as list
words <- xml_find_all(data2, "//w") #finds all w objects
xml_text(words)
word1 <- xml_find_first(data2, "//w") #finds all w objects
xml_text(word1)
xml_attrs(word1) # Find all attributes with xml_attrs()
xml_attrs(words) # Find all attributes with xml_attrs()
xml_attr(word1, attr = "pos") # Find pos attribute with xml_attr()
xml_attr(words, attr = "pos") # Find pos attribute for all w nodes
words <- xml_find_all(data2, "//w") #finds all w objects
words_c <- xml_text(words)
word_id <- xml_attr(words, attr = "n")
pos_attr <- xml_attr(words, attr = "pos")
verified_attr <- xml_attr(words, attr = "verified")
words_df <- tibble(words_c, word_id, pos_attr, verified_attr)
articles <- xml_find_all(data2, "//article")
#articles_c <- xml_text(articles)
article_id <- xml_attr(articles, attr = "n")
dialect_attr <- xml_attr(articles, attr = "dialect")
title_attr <- xml_attr(articles, attr = "title")
articles_df <- tibble(article_id, dialect_attr, title_attr)
sentences <- xml_find_all(data2, "//s")
sentences_c <- xml_text(sentences) #El problema es que no hay un contenido de la frase, sino que pega las diferentes palabras
sentences_id <- xml_attr(sentences, attr = "n")
sentences_df <- tibble(sentences_id, sentences_c)
words_df
articles_df
sentences_df
xml_structure(data2)
xml_structure(data2) %>% head()
xml_structure(data2) %>% head(n=1)
library(XML)
xmlTreeParse(data2)
xmlTreeParse(data2) %>%
?xmlTreeParse
?xmlTreeParse
xmlTreeParse(data2) %>% head(n=1)
words_df %>%
count(pos, sort = T) %>%
mutate(pos = reorder(pos, n)) %>%
ggplot(aes(pos, n)) +
geom_col() +
coord_flip()
words_df
words_df %>%
count(pos_attr, sort = T) %>%
mutate(pos_attr = reorder(pos_attr, n)) %>%
ggplot(aes(pos_attr, n)) +
geom_col() +
coord_flip()
words_df
words_df <- tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id")) %>%
mutate(sentence_id = str_c(article_id, "-", sentence_id))
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
mutate(article_id = word_id) %>%
separate(article_id, into = c("article_id", "sentence_id", "word")) %>%
mutate(sentence_id = str_c(article_id, "-", sentence_id)) %>%
select(-word)
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
?lead
words_df %>%
distinct(pos_attr)
words_df %>%
count(pos_attr, sort = T)
unique(words_df$pos_attr)
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_next = lag(words_c),
word_after = lead(words_c))
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_next = lag(words_c),
word_after = lead(words_c),
pos_next = lag(pos_attr),
pos_after = lead(pos_attr))
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) %>%
filter(pos_before == "PPOSAT" & pos_attr == "NN")
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) %>%
filter(pos_before == "PPOSAT" & pos_attr == "NN") %>%
count(word_before, words_c, sort = T)
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) #%>%
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) %>%
tail()
add_2 <- function(x) {
x + 2
}
add_2(5)
?join
library(tidyverse)
?join
?anti_join
install.packages("swirl")
library(swirl)
install_course_github(
"Carlotadbm",
"Tools_for_text_analysis")
swirl()
setwd("~/switchdrive/Shapefiles/CHE_adm")
kafi
switzerland <- st_read("CHE_adm1.shp")
switzerland #32%
switzerland %>% #47%
filter(!NAME_1 %in% c("Genève", "Jura", "Neuchâtel", "Ticino", "Vaud"))
switzerland %>% #47%
filter(!NAME_1 %in% c("Genève", "Jura", "Neuchâtel", "Ticino", "Vaud")) %>%
left_join(kafi, by = c("NAME_1" = "Canton"))
deutschweiz <-  switzerland %>% #47%
filter(!NAME_1 %in% c("Genève", "Jura", "Neuchâtel", "Ticino", "Vaud")) %>%
left_join(kafi, by = c("NAME_1" = "Canton"))
deutschweiz
ggplot() +
geom_sf(data = switzerland)
ggplot() +
#geom_sf(data = switzerland) + #74%, tarda
geom_sf(data = deutschweiz, aes(fill = Kafi_gender))
ggplot() +
geom_sf(data = switzerland) + #74%, tarda
geom_sf(data = deutschweiz, aes(fill = Kafi_gender))
ggplot() +
geom_sf(data = switzerland) + #74%, tarda
geom_sf(data = deutschweiz, aes(fill = Kafi_gender)) + #68% (y tarda un poquito)
scale_fill_manual(values = wes_palette(n = 3, name = "Royal1"))
ggplot() +
geom_sf(data = switzerland) + #74%, tarda
geom_sf(data = deutschweiz, aes(fill = Kafi_gender)) + #68% (y tarda un poquito)
scale_fill_manual(values = wes_palette(n = 3, name = "Royal1")) + #79 %
labs(title = "Gender of 'Kafi' in Swiss German (SDS)")
ggplot() +
geom_sf(data = switzerland) + #74%, tarda
geom_sf(data = deutschweiz, aes(fill = Kafi_gender)) + #68% (y tarda un poquito)
scale_fill_manual(values = wes_palette(n = 3, name = "Royal1")) + #79 %
labs(title = "Gender of 'Kafi' in Swiss German (SDS)") + #84%
theme_bw()
ggplot() +
geom_sf(data = switzerland) + #74%, tarda
geom_sf(data = deutschweiz, aes(fill = Kafi_gender)) + #68% (y tarda un poquito)
scale_fill_manual(values = wes_palette(n = 3, name = "Royal1")) + #79 %
labs(title = "Gender of 'Kafi' in Swiss German (SDS)") + #84%
theme_bw() + #89%
theme(panel.grid = element_blank(),
panel.border = element_blank(),
axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
legend.title = element_blank(),
legend.position = c(1, 0),
legend.justification = c(1, 0)) #95 %
setwd("~/switchdrive/Shapefiles/Spain_ESP_adm copia")
swiel()
swirl()
subjects
subjects %>%
mutate(percentage_pl = pl/total*100)
subjects %>%
#mutate(percentage_pl = pl/total*100)
mutate(percentage_pl = round(pl/total*100, 1))
subjects <- subjects %>%
#mutate(percentage_pl = pl/total*100)
mutate(percentage_pl = round(pl/total*100, 1))
spain <- st_read("ESP_adm1.shp")
spain_sdf <- as_Spatial(spain$geometry) #35%
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl))
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2)
spain
spain_sdf
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl))
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2)
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2) +
coord_map()
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2) +
coord_map() +#70%
scale_fill_gradient(low = "lightgrey", high = "tomato")
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2) +
coord_map() +#70%
scale_fill_gradient(low = "lightgrey", high = "tomato") +
labs(title = "Plural agreement with singular subjects (COSER)", fill = "% pl")
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2) +
coord_map() +#70%
scale_fill_gradient(low = "lightgrey", high = "tomato") +
labs(title = "Plural agreement with singular subjects (COSER)", fill = "% pl") +
theme_bw()
ggplot() +
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2) +
coord_map() +#70%
scale_fill_gradient(low = "lightgrey", high = "tomato") +
labs(title = "Plural agreement with singular subjects (COSER)", fill = "% pl") +
theme_bw() +
theme(panel.grid = element_blank(),
panel.border = element_blank(),
axis.title = element_blank(),
axis.text  = element_blank(),
axis.ticks = element_blank(),
legend.position = c(1, 0),
legend.justification = c(1, 0)) #90%
ggplot() +
#geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl)) + #55%
geom_voronoi(data = subjects, aes(x = longitude, y = latitude, fill = percentage_pl), outline = spain_sdf) + #95%
geom_text(data = subjects, aes(x = longitude, y = latitude, label = total), size = 2) +
coord_map() +#70%
scale_fill_gradient(low = "lightgrey", high = "tomato") +
labs(title = "Plural agreement with singular subjects (COSER)", fill = "% pl") +
theme_bw() +
theme(panel.grid = element_blank(),
panel.border = element_blank(),
axis.title = element_blank(),
axis.text  = element_blank(),
axis.ticks = element_blank(),
legend.position = c(1, 0),
legend.justification = c(1, 0)) #90%
